{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPOxZBNDxw919MpG2hOQw7f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/github1siva/neo4j_Chatbot_resume/blob/main/emp_resumes_emp_data_Knowledge_graph_Q%26A_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Cf5w9dpa0xmB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "510cec07-afc5-4c6b-c5e7-92f288ed9f98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.9/302.9 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m95.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyresparser"
      ],
      "metadata": {
        "id": "ftsI1Vbq03qg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5fc8239-758c-4be9-9c42-320955171d15"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyresparser\n",
            "  Downloading pyresparser-1.0.6-py3-none-any.whl (4.2 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/4.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/4.2 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m3.2/4.2 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (23.1.0)\n",
            "Requirement already satisfied: blis>=0.2.4 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (0.7.11)\n",
            "Requirement already satisfied: certifi>=2019.6.16 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (2023.11.17)\n",
            "Requirement already satisfied: chardet>=3.0.4 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (5.2.0)\n",
            "Requirement already satisfied: cymem>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (2.0.8)\n",
            "Collecting docx2txt>=0.7 (from pyresparser)\n",
            "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (3.6)\n",
            "Requirement already satisfied: jsonschema>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (4.19.2)\n",
            "Requirement already satisfied: nltk>=3.4.3 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (3.8.1)\n",
            "Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (1.23.5)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (1.5.3)\n",
            "Collecting pdfminer.six>=20181108 (from pyresparser)\n",
            "  Downloading pdfminer.six-20221105-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m109.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: preshed>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (3.0.9)\n",
            "Collecting pycryptodome>=3.8.2 (from pyresparser)\n",
            "  Downloading pycryptodome-3.19.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyrsistent>=0.15.2 (from pyresparser)\n",
            "  Downloading pyrsistent-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2019.1 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (2023.3.post1)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (2.31.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (1.16.0)\n",
            "Requirement already satisfied: sortedcontainers>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (2.4.0)\n",
            "Requirement already satisfied: spacy>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (3.6.1)\n",
            "Requirement already satisfied: srsly>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (2.4.8)\n",
            "Requirement already satisfied: thinc>=7.0.4 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (8.1.12)\n",
            "Requirement already satisfied: tqdm>=4.32.2 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (4.66.1)\n",
            "Requirement already satisfied: urllib3>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (2.0.7)\n",
            "Requirement already satisfied: wasabi>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (1.1.2)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0.1->pyresparser) (2023.11.2)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0.1->pyresparser) (0.31.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0.1->pyresparser) (0.13.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.4.3->pyresparser) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.4.3->pyresparser) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.4.3->pyresparser) (2023.6.3)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six>=20181108->pyresparser) (3.3.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six>=20181108->pyresparser) (41.0.7)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from preshed>=2.0.1->pyresparser) (1.0.10)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.1.4->pyresparser) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.1.4->pyresparser) (1.0.5)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.1.4->pyresparser) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.1.4->pyresparser) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.1.4->pyresparser) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.1.4->pyresparser) (6.4.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.1.4->pyresparser) (2.5.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.1.4->pyresparser) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy>=2.1.4->pyresparser) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.1.4->pyresparser) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.1.4->pyresparser) (3.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc>=7.0.4->pyresparser) (0.1.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six>=20181108->pyresparser) (1.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.1.4->pyresparser) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.14.5 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.1.4->pyresparser) (2.14.5)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.1.4->pyresparser) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy>=2.1.4->pyresparser) (2.1.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six>=20181108->pyresparser) (2.21)\n",
            "Building wheels for collected packages: docx2txt\n",
            "  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3960 sha256=34872040cb1cc29f64df0d7daed8bfde29297101a050bf89b40e06261764b41f\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/58/cf/093d0a6c3ecfdfc5f6ddd5524043b88e59a9a199cb02352966\n",
            "Successfully built docx2txt\n",
            "Installing collected packages: docx2txt, pyrsistent, pycryptodome, pdfminer.six, pyresparser\n",
            "Successfully installed docx2txt-0.8 pdfminer.six-20221105 pycryptodome-3.19.0 pyresparser-1.0.6 pyrsistent-0.20.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install spacy"
      ],
      "metadata": {
        "id": "o4J9Aiij1H2I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e48dae11-3918-4f12-eca4-201208d55f58"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.5.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.14.5 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.14.5)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.11.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz"
      ],
      "metadata": {
        "id": "XKLJhSSt1HuO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43b24b20-7933-4e36-941b-774635d39e2f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz (12.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting spacy<2.4.0,>=2.3.0 (from en-core-web-sm==2.3.1)\n",
            "  Downloading spacy-2.3.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (3.0.9)\n",
            "Collecting thinc<7.5.0,>=7.4.1 (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1)\n",
            "  Downloading thinc-7.4.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (0.7.11)\n",
            "Collecting wasabi<1.1.0,>=0.4.0 (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1)\n",
            "  Downloading wasabi-0.10.1-py3-none-any.whl (26 kB)\n",
            "Collecting srsly<1.1.0,>=1.0.2 (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1)\n",
            "  Downloading srsly-1.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (369 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m369.2/369.2 kB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting catalogue<1.1.0,>=0.0.7 (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1)\n",
            "  Downloading catalogue-1.0.2-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (4.66.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (67.7.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (1.23.5)\n",
            "Collecting plac<1.2.0,>=0.9.6 (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1)\n",
            "  Downloading plac-1.1.3-py2.py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (2023.11.17)\n",
            "Building wheels for collected packages: en-core-web-sm\n",
            "  Building wheel for en-core-web-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-sm: filename=en_core_web_sm-2.3.1-py3-none-any.whl size=12047086 sha256=9e4d048cc2b3248d461cef8efeb196b70432118804e9e0c93734181b892f75ca\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/1f/0e/16fae4b01d2d87454e0f484e58c48793efcf237f0894c1c4bd\n",
            "Successfully built en-core-web-sm\n",
            "Installing collected packages: wasabi, plac, srsly, catalogue, thinc, spacy, en-core-web-sm\n",
            "  Attempting uninstall: wasabi\n",
            "    Found existing installation: wasabi 1.1.2\n",
            "    Uninstalling wasabi-1.1.2:\n",
            "      Successfully uninstalled wasabi-1.1.2\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 2.4.8\n",
            "    Uninstalling srsly-2.4.8:\n",
            "      Successfully uninstalled srsly-2.4.8\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 2.0.10\n",
            "    Uninstalling catalogue-2.0.10:\n",
            "      Successfully uninstalled catalogue-2.0.10\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.1.12\n",
            "    Uninstalling thinc-8.1.12:\n",
            "      Successfully uninstalled thinc-8.1.12\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.6.1\n",
            "    Uninstalling spacy-3.6.1:\n",
            "      Successfully uninstalled spacy-3.6.1\n",
            "  Attempting uninstall: en-core-web-sm\n",
            "    Found existing installation: en-core-web-sm 3.6.0\n",
            "    Uninstalling en-core-web-sm-3.6.0:\n",
            "      Successfully uninstalled en-core-web-sm-3.6.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "confection 0.1.4 requires srsly<3.0.0,>=2.4.0, but you have srsly 1.0.7 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed catalogue-1.0.2 en-core-web-sm-2.3.1 plac-1.1.3 spacy-2.3.9 srsly-1.0.7 thinc-7.4.6 wasabi-0.10.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install py2neo"
      ],
      "metadata": {
        "id": "dUmzoZLS1Hic",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "beb6d1e8-10ee-454e-afb8-aaa70fcb46e9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting py2neo\n",
            "  Downloading py2neo-2021.2.4-py2.py3-none-any.whl (177 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.2/177.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from py2neo) (2023.11.17)\n",
            "Collecting interchange~=2021.0.4 (from py2neo)\n",
            "  Downloading interchange-2021.0.4-py2.py3-none-any.whl (28 kB)\n",
            "Collecting monotonic (from py2neo)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from py2neo) (23.2)\n",
            "Collecting pansi>=2020.7.3 (from py2neo)\n",
            "  Downloading pansi-2020.7.3-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: pygments>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from py2neo) (2.16.1)\n",
            "Requirement already satisfied: six>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from py2neo) (1.16.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from py2neo) (2.0.7)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from interchange~=2021.0.4->py2neo) (2023.3.post1)\n",
            "Installing collected packages: monotonic, pansi, interchange, py2neo\n",
            "Successfully installed interchange-2021.0.4 monotonic-1.6 pansi-2020.7.3 py2neo-2021.2.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-generativeai"
      ],
      "metadata": {
        "id": "8mmQMCJI1SeP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a77a423-3e29-4446-e541-54f673c41151"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.10/dist-packages (0.2.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.3.3 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (0.3.3)\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.17.3)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.11.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (3.20.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.66.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.3.3->google-generativeai) (1.22.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.61.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (2.31.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai) (4.9)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.59.3)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.48.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth->google-generativeai) (0.5.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2023.11.17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install neo4j"
      ],
      "metadata": {
        "id": "pkwclH3J20m0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37788345-7b93-43e3-d3ac-ad74b4355302"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting neo4j\n",
            "  Downloading neo4j-5.15.0.tar.gz (196 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/196.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/196.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.5/196.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from neo4j) (2023.3.post1)\n",
            "Building wheels for collected packages: neo4j\n",
            "  Building wheel for neo4j (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for neo4j: filename=neo4j-5.15.0-py3-none-any.whl size=272484 sha256=ee89a0f27a3a691ed34db5a5c214a39bf2851ec7987168e09296db940dbf3fa1\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/08/10/6371dbdeec2efd7782f559b21c32bb6b4192ae0216ec5e39c5\n",
            "Successfully built neo4j\n",
            "Installing collected packages: neo4j\n",
            "Successfully installed neo4j-5.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q neo4j-driver"
      ],
      "metadata": {
        "id": "mIFXEKRNCN0y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6944941-9d98-4b51-81fa-65653df00097"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/196.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m194.6/196.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.6/196.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for neo4j-driver (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "7N4fgRTB1YKJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "736cd804-af34-47d0-b72d-0c3356e9b4e0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyresparser import ResumeParser\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# Specify the folder containing your resumes\n",
        "folder_path = \"resume\"\n",
        "\n",
        "# Iterate through all files in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".pdf\"):  # Check if the file is a PDF\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "\n",
        "        # Extract data from the current resume\n",
        "        data = ResumeParser(file_path).get_extracted_data()\n",
        "\n",
        "        # Print the relevant information\n",
        "        print(f\"\\nResume: {filename}\")\n",
        "        print(\"Name:\", data[\"name\"])\n",
        "        print(\"Email:\", data[\"email\"])\n",
        "        print(\"Mobile Number:\", data[\"mobile_number\"])\n",
        "        print(\"Skills:\", data[\"skills\"])"
      ],
      "metadata": {
        "id": "n488gVr-BBPq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b31e1ac-ff73-41be-db3c-2d6e4e89f8ca"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Resume: ID1.pdf\n",
            "Name: John Whilliam\n",
            "Email: johnwilliams@gmail.com\n",
            "Mobile Number: 456-7891\n",
            "Skills: ['Analysis', 'Modeling', 'Statistics', 'Tableau', 'Datasets', 'Python', 'Hospital', 'Mining', 'Machine learning', 'Mysql', 'Scala', 'Spacy']\n",
            "\n",
            "Resume: ID6.pdf\n",
            "Name: Omkar Pathak\n",
            "Email: omkarpathak27@gmail.com\n",
            "Mobile Number: 8087996634\n",
            "Skills: ['Unix', 'Migration', 'Operating systems', 'Reports', 'Content', 'Javascript', 'Automation', 'Apis', 'Html', 'Linux', 'Excel', 'Flask', 'System', 'Writing', 'Windows', 'Programming', 'Api', 'Opencv', 'Security', 'Scrum', 'Cloud', 'Github', 'Auditing', 'Php', 'Parser', 'Engineering', 'Algorithms', 'Python', 'Shell', 'Machine learning', 'Training', 'C++', 'C', 'Photography', 'Analytics', 'Django', 'Technical', 'Css', 'Website', 'Testing', 'Mysql']\n",
            "\n",
            "Resume: ID5.pdf\n",
            "Name: David Robinson\n",
            "Email: d.robinson@email.com\n",
            "Mobile Number: 456-7890\n",
            "Skills: ['Computer science', 'Spacy', 'Hadoop', 'Modeling', 'Pytorch', 'Programming', 'Matplotlib', 'Etl', 'Datasets', 'Python', 'Hospital', 'Analytical', 'Pandas', 'Tableau', 'Improvement', 'Interactive', 'Seaborn', 'Research', 'Key performance indicators', 'Aws', 'Testing', 'Mysql', 'Conversion']\n",
            "\n",
            "Resume: ID4.pdf\n",
            "Name: KANDACE LOUDOR\n",
            "Email: kloudor@email.com\n",
            "Mobile Number: 456-7894\n",
            "Skills: ['Retention', 'Marketing', 'Numpy', 'Flask', 'Keras', 'Statistics', 'Segmentation', 'Programming', 'Python', 'Sql', 'Analytical', 'Aws', 'Ordering', 'Pandas', 'Mysql', 'Process', 'Forecasting']\n",
            "\n",
            "Resume: ID2.pdf\n",
            "Name: Emma Davis\n",
            "Email: e.davis@email.com\n",
            "Mobile Number: 456-7892\n",
            "Skills: ['Computer science', 'Analyze', 'Docker', 'Hadoop', 'Nltk', 'Sql', 'Analysis', 'Adobe', 'Etl', 'Datasets', 'Tensorflow', 'Python', 'Cisco', 'Pandas', 'Machine learning', 'Warehouse', 'Forecasting', 'Retention', 'Marketing', 'Improvement', 'Aws', 'Data analysis']\n",
            "\n",
            "Resume: ID3.pdf\n",
            "Name: Trish Mathers\n",
            "Email: tmathers@email.com\n",
            "Mobile Number: 456-7893\n",
            "Skills: ['Analysis', 'Excel', 'Sas', 'Mathematics', 'Modeling', 'Programming', 'Sql', 'Economics']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyresparser import ResumeParser\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# Specify the folder containing your resumes\n",
        "folder_path = \"resume\"\n",
        "\n",
        "# Iterate through all files in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".pdf\"):  # Check if the file is a PDF\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "\n",
        "        # Extract data from the current resume\n",
        "        data = ResumeParser(file_path).get_extracted_data()\n",
        "\n",
        "        # Remove \".pdf\" extension and extract employee ID\n",
        "        employee_id = os.path.splitext(filename)[0]\n",
        "\n",
        "        # Print the relevant information\n",
        "        print(f\"\\nResume_Name: {filename}\")\n",
        "        print(f\"Resume_Id: {employee_id}\")\n",
        "        print(\"Name:\", data[\"name\"])\n",
        "        print(\"Email:\", data[\"email\"])\n",
        "        print(\"Mobile Number:\", data[\"mobile_number\"])\n",
        "        print(\"Skills:\", data[\"skills\"])\n"
      ],
      "metadata": {
        "id": "eF9LTXKRBBMI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27b258d3-c821-4cce-a290-66dad6193365"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Resume_Name: ID1.pdf\n",
            "Resume_Id: ID1\n",
            "Name: John Whilliam\n",
            "Email: johnwilliams@gmail.com\n",
            "Mobile Number: 456-7891\n",
            "Skills: ['Analysis', 'Modeling', 'Statistics', 'Tableau', 'Datasets', 'Python', 'Hospital', 'Mining', 'Machine learning', 'Mysql', 'Scala', 'Spacy']\n",
            "\n",
            "Resume_Name: ID6.pdf\n",
            "Resume_Id: ID6\n",
            "Name: Omkar Pathak\n",
            "Email: omkarpathak27@gmail.com\n",
            "Mobile Number: 8087996634\n",
            "Skills: ['Unix', 'Migration', 'Operating systems', 'Reports', 'Content', 'Javascript', 'Automation', 'Apis', 'Html', 'Linux', 'Excel', 'Flask', 'System', 'Writing', 'Windows', 'Programming', 'Api', 'Opencv', 'Security', 'Scrum', 'Cloud', 'Github', 'Auditing', 'Php', 'Parser', 'Engineering', 'Algorithms', 'Python', 'Shell', 'Machine learning', 'Training', 'C++', 'C', 'Photography', 'Analytics', 'Django', 'Technical', 'Css', 'Website', 'Testing', 'Mysql']\n",
            "\n",
            "Resume_Name: ID5.pdf\n",
            "Resume_Id: ID5\n",
            "Name: David Robinson\n",
            "Email: d.robinson@email.com\n",
            "Mobile Number: 456-7890\n",
            "Skills: ['Computer science', 'Spacy', 'Hadoop', 'Modeling', 'Pytorch', 'Programming', 'Matplotlib', 'Etl', 'Datasets', 'Python', 'Hospital', 'Analytical', 'Pandas', 'Tableau', 'Improvement', 'Interactive', 'Seaborn', 'Research', 'Key performance indicators', 'Aws', 'Testing', 'Mysql', 'Conversion']\n",
            "\n",
            "Resume_Name: ID4.pdf\n",
            "Resume_Id: ID4\n",
            "Name: KANDACE LOUDOR\n",
            "Email: kloudor@email.com\n",
            "Mobile Number: 456-7894\n",
            "Skills: ['Retention', 'Marketing', 'Numpy', 'Flask', 'Keras', 'Statistics', 'Segmentation', 'Programming', 'Python', 'Sql', 'Analytical', 'Aws', 'Ordering', 'Pandas', 'Mysql', 'Process', 'Forecasting']\n",
            "\n",
            "Resume_Name: ID2.pdf\n",
            "Resume_Id: ID2\n",
            "Name: Emma Davis\n",
            "Email: e.davis@email.com\n",
            "Mobile Number: 456-7892\n",
            "Skills: ['Computer science', 'Analyze', 'Docker', 'Hadoop', 'Nltk', 'Sql', 'Analysis', 'Adobe', 'Etl', 'Datasets', 'Tensorflow', 'Python', 'Cisco', 'Pandas', 'Machine learning', 'Warehouse', 'Forecasting', 'Retention', 'Marketing', 'Improvement', 'Aws', 'Data analysis']\n",
            "\n",
            "Resume_Name: ID3.pdf\n",
            "Resume_Id: ID3\n",
            "Name: Trish Mathers\n",
            "Email: tmathers@email.com\n",
            "Mobile Number: 456-7893\n",
            "Skills: ['Analysis', 'Excel', 'Sas', 'Mathematics', 'Modeling', 'Programming', 'Sql', 'Economics']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyresparser import ResumeParser\n",
        "import os\n",
        "import pandas as pd\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# Specify the folder containing your resumes\n",
        "folder_path = \"resume\"\n",
        "csv_file_path = \"emp_data.csv\"  # Path to your CSV file\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "employee_data = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Iterate through all files in the resume folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".pdf\"):  # Check if the file is a PDF\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "\n",
        "        # Extract data from the current resume\n",
        "        data = ResumeParser(file_path).get_extracted_data()\n",
        "\n",
        "        # Remove \".pdf\" extension and extract employee ID\n",
        "        employee_id = os.path.splitext(filename)[0]\n",
        "\n",
        "        # Check if there's corresponding employee data in the CSV\n",
        "        employee_row = employee_data[employee_data['Employee_id'] == employee_id]\n",
        "\n",
        "        if not employee_row.empty:\n",
        "            # Check if the Name from the resume matches Employee_name\n",
        "            if data[\"name\"].lower() == employee_row['Employee_name'].values[0].lower():\n",
        "                # Print the relevant information\n",
        "                print(f\"\\nResume_Name: {filename}\")\n",
        "                print(f\"Employee_Id: {employee_id}\")\n",
        "                print(\"Employee Name:\", employee_row['Employee_name'].values[0])\n",
        "                print(\"Employee Experience:\", employee_row['Employee_experience'].values[0])\n",
        "                print(\"Bench:\", employee_row['Bench(yes/no)'].values[0])\n",
        "                print(\"Employee Role:\", employee_row['Employee_role'].values[0])\n",
        "                print(\"Email:\", data[\"email\"])\n",
        "                print(\"Mobile Number:\", data[\"mobile_number\"])\n",
        "                print(\"Skills:\", data[\"skills\"])\n",
        "            else:\n",
        "                print(f\"\\nName from resume does not match Employee_name for Resume_Id: {employee_id}\")\n",
        "        else:\n",
        "            print(f\"No employee data found for Resume_Id: {employee_id}\")\n"
      ],
      "metadata": {
        "id": "VwonUJecBBJi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a512ae84-63ed-4b2d-accc-7b3d597a95f8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Resume_Name: ID1.pdf\n",
            "Employee_Id: ID1\n",
            "Employee Name: John Whilliam\n",
            "Employee Experience: 5\n",
            "Bench: yes\n",
            "Employee Role: Software Engineer\n",
            "Email: johnwilliams@gmail.com\n",
            "Mobile Number: 456-7891\n",
            "Skills: ['Analysis', 'Modeling', 'Statistics', 'Tableau', 'Datasets', 'Python', 'Hospital', 'Mining', 'Machine learning', 'Mysql', 'Scala', 'Spacy']\n",
            "\n",
            "Resume_Name: ID6.pdf\n",
            "Employee_Id: ID6\n",
            "Employee Name: Omkar Pathak\n",
            "Employee Experience: 5\n",
            "Bench: yes\n",
            "Employee Role: Senior Data Scientist\n",
            "Email: omkarpathak27@gmail.com\n",
            "Mobile Number: 8087996634\n",
            "Skills: ['Unix', 'Migration', 'Operating systems', 'Reports', 'Content', 'Javascript', 'Automation', 'Apis', 'Html', 'Linux', 'Excel', 'Flask', 'System', 'Writing', 'Windows', 'Programming', 'Api', 'Opencv', 'Security', 'Scrum', 'Cloud', 'Github', 'Auditing', 'Php', 'Parser', 'Engineering', 'Algorithms', 'Python', 'Shell', 'Machine learning', 'Training', 'C++', 'C', 'Photography', 'Analytics', 'Django', 'Technical', 'Css', 'Website', 'Testing', 'Mysql']\n",
            "\n",
            "Resume_Name: ID5.pdf\n",
            "Employee_Id: ID5\n",
            "Employee Name: David Robinson\n",
            "Employee Experience: 10\n",
            "Bench: no\n",
            "Employee Role: Senior Software Engineer\n",
            "Email: d.robinson@email.com\n",
            "Mobile Number: 456-7890\n",
            "Skills: ['Computer science', 'Spacy', 'Hadoop', 'Modeling', 'Pytorch', 'Programming', 'Matplotlib', 'Etl', 'Datasets', 'Python', 'Hospital', 'Analytical', 'Pandas', 'Tableau', 'Improvement', 'Interactive', 'Seaborn', 'Research', 'Key performance indicators', 'Aws', 'Testing', 'Mysql', 'Conversion']\n",
            "\n",
            "Resume_Name: ID4.pdf\n",
            "Employee_Id: ID4\n",
            "Employee Name: KANDACE LOUDOR\n",
            "Employee Experience: 6\n",
            "Bench: no\n",
            "Employee Role: Data Scientist\n",
            "Email: kloudor@email.com\n",
            "Mobile Number: 456-7894\n",
            "Skills: ['Retention', 'Marketing', 'Numpy', 'Flask', 'Keras', 'Statistics', 'Segmentation', 'Programming', 'Python', 'Sql', 'Analytical', 'Aws', 'Ordering', 'Pandas', 'Mysql', 'Process', 'Forecasting']\n",
            "\n",
            "Resume_Name: ID2.pdf\n",
            "Employee_Id: ID2\n",
            "Employee Name: Emma Davis\n",
            "Employee Experience: 8\n",
            "Bench: no\n",
            "Employee Role: Project Manager\n",
            "Email: e.davis@email.com\n",
            "Mobile Number: 456-7892\n",
            "Skills: ['Computer science', 'Analyze', 'Docker', 'Hadoop', 'Nltk', 'Sql', 'Analysis', 'Adobe', 'Etl', 'Datasets', 'Tensorflow', 'Python', 'Cisco', 'Pandas', 'Machine learning', 'Warehouse', 'Forecasting', 'Retention', 'Marketing', 'Improvement', 'Aws', 'Data analysis']\n",
            "\n",
            "Resume_Name: ID3.pdf\n",
            "Employee_Id: ID3\n",
            "Employee Name: Trish Mathers\n",
            "Employee Experience: 3\n",
            "Bench: yes\n",
            "Employee Role: Business Analyst\n",
            "Email: tmathers@email.com\n",
            "Mobile Number: 456-7893\n",
            "Skills: ['Analysis', 'Excel', 'Sas', 'Mathematics', 'Modeling', 'Programming', 'Sql', 'Economics']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyresparser import ResumeParser\n",
        "import os\n",
        "import pandas as pd\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# Specify the folder containing your resumes\n",
        "folder_path = \"resume\"\n",
        "csv_file_path = \"emp_data.csv\"  # Path to your CSV file\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "employee_data = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Create lists to store extracted information\n",
        "resume_names = []\n",
        "employee_ids = []\n",
        "employee_names = []\n",
        "employee_experiences = []\n",
        "benches = []\n",
        "employee_roles = []\n",
        "emails = []\n",
        "mobile_numbers = []\n",
        "skills_list = []\n",
        "\n",
        "# Iterate through all files in the resume folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".pdf\"):  # Check if the file is a PDF\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "\n",
        "        # Extract data from the current resume\n",
        "        data = ResumeParser(file_path).get_extracted_data()\n",
        "\n",
        "        # Remove \".pdf\" extension and extract employee ID\n",
        "        employee_id = os.path.splitext(filename)[0]\n",
        "\n",
        "        # Check if there's corresponding employee data in the CSV\n",
        "        employee_row = employee_data[employee_data['Employee_id'] == employee_id]\n",
        "\n",
        "        if not employee_row.empty:\n",
        "            # Check if the Name from the resume matches Employee_name\n",
        "            if data[\"name\"].lower() == employee_row['Employee_name'].values[0].lower():\n",
        "                # Append the relevant information to lists\n",
        "                resume_names.append(filename)\n",
        "                employee_ids.append(employee_id)\n",
        "                employee_names.append(employee_row['Employee_name'].values[0])\n",
        "                employee_experiences.append(employee_row['Employee_experience'].values[0])\n",
        "                benches.append(employee_row['Bench(yes/no)'].values[0])\n",
        "                employee_roles.append(employee_row['Employee_role'].values[0])\n",
        "                emails.append(data[\"email\"])\n",
        "                mobile_numbers.append(data[\"mobile_number\"])\n",
        "                skills_list.append(data[\"skills\"])\n",
        "\n",
        "                # Print the relevant information\n",
        "                print(f\"\\nResume_Name: {filename}\")\n",
        "                print(f\"Employee_Id: {employee_id}\")\n",
        "                print(\"Employee Name:\", employee_row['Employee_name'].values[0])\n",
        "                print(\"Employee Experience:\", employee_row['Employee_experience'].values[0])\n",
        "                print(\"Bench:\", employee_row['Bench(yes/no)'].values[0])\n",
        "                print(\"Employee Role:\", employee_row['Employee_role'].values[0])\n",
        "                print(\"Email:\", data[\"email\"])\n",
        "                print(\"Mobile Number:\", data[\"mobile_number\"])\n",
        "                print(\"Skills:\", data[\"skills\"])\n",
        "            else:\n",
        "                print(f\"\\nName from resume does not match Employee_name for Resume_Id: {employee_id}\")\n",
        "        else:\n",
        "            print(f\"No employee data found for Resume_Id: {employee_id}\")\n",
        "\n",
        "# Create a DataFrame from the lists\n",
        "output_df = pd.DataFrame({\n",
        "    \"Resume_Name\": resume_names,\n",
        "    \"Employee_Id\": employee_ids,\n",
        "    \"Employee_Name\": employee_names,\n",
        "    \"Employee_Experience\": employee_experiences,\n",
        "    \"Bench\": benches,\n",
        "    \"Employee_Role\": employee_roles,\n",
        "    \"Email\": emails,\n",
        "    \"Mobile_Number\": mobile_numbers,\n",
        "    \"Skills\": skills_list\n",
        "})\n",
        "\n",
        "# Print the DataFrame\n",
        "print(\"\\nOutput DataFrame:\")\n",
        "print(output_df)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "output_csv_path = \"output_data.csv\"\n",
        "output_df.to_csv(output_csv_path, index=False)\n",
        "\n",
        "print(f\"\\nOutput saved to {output_csv_path}\")"
      ],
      "metadata": {
        "id": "TZxq8vC2BBHC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c1738ff-8010-48d4-da94-b50f731e6c0e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Resume_Name: ID1.pdf\n",
            "Employee_Id: ID1\n",
            "Employee Name: John Whilliam\n",
            "Employee Experience: 5\n",
            "Bench: yes\n",
            "Employee Role: Software Engineer\n",
            "Email: johnwilliams@gmail.com\n",
            "Mobile Number: 456-7891\n",
            "Skills: ['Analysis', 'Modeling', 'Statistics', 'Tableau', 'Datasets', 'Python', 'Hospital', 'Mining', 'Machine learning', 'Mysql', 'Scala', 'Spacy']\n",
            "\n",
            "Resume_Name: ID6.pdf\n",
            "Employee_Id: ID6\n",
            "Employee Name: Omkar Pathak\n",
            "Employee Experience: 5\n",
            "Bench: yes\n",
            "Employee Role: Senior Data Scientist\n",
            "Email: omkarpathak27@gmail.com\n",
            "Mobile Number: 8087996634\n",
            "Skills: ['Unix', 'Migration', 'Operating systems', 'Reports', 'Content', 'Javascript', 'Automation', 'Apis', 'Html', 'Linux', 'Excel', 'Flask', 'System', 'Writing', 'Windows', 'Programming', 'Api', 'Opencv', 'Security', 'Scrum', 'Cloud', 'Github', 'Auditing', 'Php', 'Parser', 'Engineering', 'Algorithms', 'Python', 'Shell', 'Machine learning', 'Training', 'C++', 'C', 'Photography', 'Analytics', 'Django', 'Technical', 'Css', 'Website', 'Testing', 'Mysql']\n",
            "\n",
            "Resume_Name: ID5.pdf\n",
            "Employee_Id: ID5\n",
            "Employee Name: David Robinson\n",
            "Employee Experience: 10\n",
            "Bench: no\n",
            "Employee Role: Senior Software Engineer\n",
            "Email: d.robinson@email.com\n",
            "Mobile Number: 456-7890\n",
            "Skills: ['Computer science', 'Spacy', 'Hadoop', 'Modeling', 'Pytorch', 'Programming', 'Matplotlib', 'Etl', 'Datasets', 'Python', 'Hospital', 'Analytical', 'Pandas', 'Tableau', 'Improvement', 'Interactive', 'Seaborn', 'Research', 'Key performance indicators', 'Aws', 'Testing', 'Mysql', 'Conversion']\n",
            "\n",
            "Resume_Name: ID4.pdf\n",
            "Employee_Id: ID4\n",
            "Employee Name: KANDACE LOUDOR\n",
            "Employee Experience: 6\n",
            "Bench: no\n",
            "Employee Role: Data Scientist\n",
            "Email: kloudor@email.com\n",
            "Mobile Number: 456-7894\n",
            "Skills: ['Retention', 'Marketing', 'Numpy', 'Flask', 'Keras', 'Statistics', 'Segmentation', 'Programming', 'Python', 'Sql', 'Analytical', 'Aws', 'Ordering', 'Pandas', 'Mysql', 'Process', 'Forecasting']\n",
            "\n",
            "Resume_Name: ID2.pdf\n",
            "Employee_Id: ID2\n",
            "Employee Name: Emma Davis\n",
            "Employee Experience: 8\n",
            "Bench: no\n",
            "Employee Role: Project Manager\n",
            "Email: e.davis@email.com\n",
            "Mobile Number: 456-7892\n",
            "Skills: ['Computer science', 'Analyze', 'Docker', 'Hadoop', 'Nltk', 'Sql', 'Analysis', 'Adobe', 'Etl', 'Datasets', 'Tensorflow', 'Python', 'Cisco', 'Pandas', 'Machine learning', 'Warehouse', 'Forecasting', 'Retention', 'Marketing', 'Improvement', 'Aws', 'Data analysis']\n",
            "\n",
            "Resume_Name: ID3.pdf\n",
            "Employee_Id: ID3\n",
            "Employee Name: Trish Mathers\n",
            "Employee Experience: 3\n",
            "Bench: yes\n",
            "Employee Role: Business Analyst\n",
            "Email: tmathers@email.com\n",
            "Mobile Number: 456-7893\n",
            "Skills: ['Analysis', 'Excel', 'Sas', 'Mathematics', 'Modeling', 'Programming', 'Sql', 'Economics']\n",
            "\n",
            "Output DataFrame:\n",
            "  Resume_Name Employee_Id   Employee_Name  Employee_Experience Bench  \\\n",
            "0     ID1.pdf         ID1   John Whilliam                    5   yes   \n",
            "1     ID6.pdf         ID6    Omkar Pathak                    5   yes   \n",
            "2     ID5.pdf         ID5  David Robinson                   10    no   \n",
            "3     ID4.pdf         ID4  KANDACE LOUDOR                    6    no   \n",
            "4     ID2.pdf         ID2      Emma Davis                    8    no   \n",
            "5     ID3.pdf         ID3   Trish Mathers                    3   yes   \n",
            "\n",
            "              Employee_Role                    Email Mobile_Number  \\\n",
            "0         Software Engineer   johnwilliams@gmail.com      456-7891   \n",
            "1     Senior Data Scientist  omkarpathak27@gmail.com    8087996634   \n",
            "2  Senior Software Engineer     d.robinson@email.com      456-7890   \n",
            "3            Data Scientist        kloudor@email.com      456-7894   \n",
            "4           Project Manager        e.davis@email.com      456-7892   \n",
            "5          Business Analyst       tmathers@email.com      456-7893   \n",
            "\n",
            "                                              Skills  \n",
            "0  [Analysis, Modeling, Statistics, Tableau, Data...  \n",
            "1  [Unix, Migration, Operating systems, Reports, ...  \n",
            "2  [Computer science, Spacy, Hadoop, Modeling, Py...  \n",
            "3  [Retention, Marketing, Numpy, Flask, Keras, St...  \n",
            "4  [Computer science, Analyze, Docker, Hadoop, Nl...  \n",
            "5  [Analysis, Excel, Sas, Mathematics, Modeling, ...  \n",
            "\n",
            "Output saved to output_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from py2neo import Graph, Node, Relationship\n",
        "\n",
        "# Connect to the Neo4j database\n",
        "graph = Graph(\"bolt://18.207.214.172:7687\", auth=(\"neo4j\", \"month-fines-sirens\"))\n",
        "\n",
        "# Create nodes for employees and resumes\n",
        "for index, row in output_df.iterrows():\n",
        "    employee_node = Node(\"Employee\",\n",
        "                         Employee_Id=row[\"Employee_Id\"],\n",
        "                         Employee_Name=row[\"Employee_Name\"],\n",
        "                         Employee_Experience=row[\"Employee_Experience\"],\n",
        "                         Bench=row[\"Bench\"],\n",
        "                         Employee_Role=row[\"Employee_Role\"])\n",
        "\n",
        "    resume_node = Node(\"Resume\",\n",
        "                      Resume_Name=row[\"Resume_Name\"],\n",
        "                      Email=row[\"Email\"],\n",
        "                      Mobile_Number=row[\"Mobile_Number\"],\n",
        "                      Skills=row[\"Skills\"])\n",
        "\n",
        "    graph.create(employee_node)\n",
        "    graph.create(resume_node)\n",
        "\n",
        "    # Create a relationship between the employee and the resume\n",
        "    graph.create(Relationship(employee_node, \"HAS_RESUME\", resume_node))\n",
        "\n",
        "# Print confirmation\n",
        "print(\"Nodes and relationships created successfully.\")\n"
      ],
      "metadata": {
        "id": "7ZSsfkmmBBEV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "798a2b0c-50c2-4aa1-cf3f-3860bd6e461f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nodes and relationships created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Retrieve employees who have a specific role \"Software Engineer\".\n",
        "cypher_query = \"\"\"\n",
        "MATCH (e:Employee)\n",
        "WHERE e.Employee_Role = 'Software Engineer'\n",
        "RETURN e.Employee_Id AS employeeId, e.Employee_Name AS employeeName, e.Employee_Experience AS employeeExperience\n",
        "\"\"\"\n",
        "result = graph.run(cypher_query)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2F5BLDg0xScf",
        "outputId": "f5b2757f-7ff8-4bda-96e7-8ea20b6438aa"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " employeeId | employeeName  | employeeExperience \r\n",
            "------------|---------------|--------------------\r\n",
            " ID1        | John Whilliam |                  5 \r\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Retrieve employees who have a specific role \"Data Scientist\".\n",
        "cypher_query = \"\"\"\n",
        "MATCH (e:Employee)-[:HAS_RESUME]->(r:Resume)\n",
        "WHERE e.Employee_Role = 'Data Scientist'\n",
        "RETURN e.Employee_Id, e.Employee_Name, e.Employee_Experience, e.Bench, e.Employee_Role, r.Skills\n",
        "\"\"\"\n",
        "result = graph.run(cypher_query)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "nlowTjgbBBBb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d8e909f-d525-4a45-923f-3da86f0d3b6b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " e.Employee_Id | e.Employee_Name | e.Employee_Experience | e.Bench | e.Employee_Role | r.Skills                                                                                                                                                                                          \r\n",
            "---------------|-----------------|-----------------------|---------|-----------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\r\n",
            " ID4           | KANDACE LOUDOR  |                     6 | no      | Data Scientist  | ['Retention', 'Marketing', 'Numpy', 'Flask', 'Keras', 'Statistics', 'Segmentation', 'Programming', 'Python', 'Sql', 'Analytical', 'Aws', 'Ordering', 'Pandas', 'Mysql', 'Process', 'Forecasting'] \r\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#To retrieve employees and their resumes who know both 'Python' and 'Sql'.\n",
        "cypher_query = \"\"\"\n",
        "MATCH (e:Employee)-[:HAS_RESUME]->(r:Resume)\n",
        "WHERE 'Python' IN r.Skills AND 'Sql' IN r.Skills\n",
        "RETURN e.Employee_Id AS employeeId, e.Employee_Name AS employeeName, e.Employee_Experience AS employeeExperience, r.Skills\n",
        "\"\"\"\n",
        "result = graph.run(cypher_query)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "E9X_eB9DBA-0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a68b09b-f6c5-4bfe-a10e-90bdcc08e670"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " employeeId | employeeName   | employeeExperience | r.Skills                                                                                                                                                                                                                                                               \r\n",
            "------------|----------------|--------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\r\n",
            " ID4        | KANDACE LOUDOR |                  6 | ['Retention', 'Marketing', 'Numpy', 'Flask', 'Keras', 'Statistics', 'Segmentation', 'Programming', 'Python', 'Sql', 'Analytical', 'Aws', 'Ordering', 'Pandas', 'Mysql', 'Process', 'Forecasting']                                                                      \r\n",
            " ID2        | Emma Davis     |                  8 | ['Computer science', 'Analyze', 'Docker', 'Hadoop', 'Nltk', 'Sql', 'Analysis', 'Adobe', 'Etl', 'Datasets', 'Tensorflow', 'Python', 'Cisco', 'Pandas', 'Machine learning', 'Warehouse', 'Forecasting', 'Retention', 'Marketing', 'Improvement', 'Aws', 'Data analysis'] \r\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#To retrieve the names of employees who are on the bench.\n",
        "cypher_query = \"\"\"\n",
        "MATCH (e:Employee)\n",
        "WHERE e.Bench = 'yes'\n",
        "RETURN e.Employee_Name\n",
        "\"\"\"\n",
        "result = graph.run(cypher_query)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "tAOaF1PaBA75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "121096ff-1bd4-4012-83f8-647b9ac199c1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " e.Employee_Name \r\n",
            "-----------------\r\n",
            " John Whilliam   \r\n",
            " Omkar Pathak    \r\n",
            " Trish Mathers   \r\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#To retrieve the names of employees with high experience.\n",
        "cypher_query = \"\"\"\n",
        "MATCH (e:Employee)\n",
        "RETURN e.Employee_Name, e.Employee_Experience\n",
        "ORDER BY e.Employee_Experience DESC\n",
        "LIMIT 1\n",
        "\"\"\"\n",
        "result = graph.run(cypher_query)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "5sHLtwvlBA5P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fa6b679-3c21-4ba3-e515-e98803aa2163"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " e.Employee_Name | e.Employee_Experience \r\n",
            "-----------------|-----------------------\r\n",
            " David Robinson  |                    10 \r\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#To retrieve the names of employees with low experience.\n",
        "cypher_query = \"\"\"\n",
        "MATCH (e:Employee)\n",
        "WHERE e.Employee_Experience < 5\n",
        "RETURN e.Employee_Name, e.Employee_Experience\n",
        "ORDER BY e.Employee_Experience ASC\n",
        "LIMIT 2\n",
        "\"\"\"\n",
        "result = graph.run(cypher_query)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "xLkFlhnqBA2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a793e246-0157-4c5b-e776-eccbf1964a80"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " e.Employee_Name | e.Employee_Experience \r\n",
            "-----------------|-----------------------\r\n",
            " Trish Mathers   |                     3 \r\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as palm\n",
        "import base64\n",
        "import json\n",
        "from neo4j import GraphDatabase\n",
        "import re"
      ],
      "metadata": {
        "id": "LZ611eVqCR05"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "palm.configure(api_key = \"AIzaSyAPUt0AqHv_oRhF-uJBCAlvQgfhKe1BEjo\")"
      ],
      "metadata": {
        "id": "KIbXXR45BAz6"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_answer(input):\n",
        "\n",
        "    defaults = {\n",
        "  'model': 'models/text-bison-001',\n",
        "  'temperature': 0.7,\n",
        "  'candidate_count': 1,\n",
        "  'top_k': 40,\n",
        "  'top_p': 0.95,\n",
        "  'max_output_tokens': 1024,\n",
        "  'stop_sequences': [],\n",
        "  'safety_settings': [{\"category\":\"HARM_CATEGORY_DEROGATORY\",\"threshold\":1},{\"category\":\"HARM_CATEGORY_TOXICITY\",\"threshold\":1},{\"category\":\"HARM_CATEGORY_VIOLENCE\",\"threshold\":2},{\"category\":\"HARM_CATEGORY_SEXUAL\",\"threshold\":2},{\"category\":\"HARM_CATEGORY_MEDICAL\",\"threshold\":2},{\"category\":\"HARM_CATEGORY_DANGEROUS\",\"threshold\":2}],\n",
        "    }\n",
        "\n",
        "    prompt = f\"\"\"You are an expert in querying a Neo4j graph with the following nodes and relationships:\n",
        "            - Nodes: Employee, Resume\n",
        "            - Employee Node Properties: Employee (Employee_Id, Employee_Name, Employee_Experience, Bench, Employee_Role)\n",
        "            - Resume Node Properties: Resume (Resume_Name, Email, Mobile_Number, Skills )\n",
        "            - Relationships: HAS_RESUME start from Employee to Resume\n",
        "\n",
        "    For example,\n",
        "    Example 1 - Retrieve employees who have a specific role \"Software Engineer\", the Cypher command will be something like this\n",
        "    ```\n",
        "    MATCH (e:Employee)\n",
        "    WHERE e.Employee_Role = 'Software Engineer'\n",
        "    RETURN e.Employee_Id AS employeeId, e.Employee_Name AS employeeName, e.Employee_Experience AS employeeExperience\n",
        "    ```\n",
        "\n",
        "    Example 2 - To retrieve employees and their resumes who know both 'Python' and 'Sql'.\n",
        "\n",
        "    ```\n",
        "    MATCH (e:Employee)-[:HAS_RESUME]->(r:Resume)\n",
        "    WHERE 'Python' IN r.Skills AND 'Sql' IN r.Skills\n",
        "    RETURN e.Employee_Id AS employeeId, e.Employee_Name AS employeeName, e.Employee_Experience AS employeeExperience, r.Skills\n",
        "    ```\n",
        "\n",
        "    Example 3 - To retrieve the names of employees who are on the bench?\n",
        "    ```\n",
        "    MATCH (e:Employee)\n",
        "    WHERE e.Bench = 'yes'\n",
        "    RETURN e.Employee_Name\n",
        "    ```\n",
        "\n",
        "    Example 4 - To retrieve the names of employees with low experience?\n",
        "    ```\n",
        "    MATCH (e:Employee)\n",
        "    WHERE e.Employee_Experience < 5\n",
        "    RETURN e.Employee_Name, e.Employee_Experience\n",
        "    ORDER BY e.Employee_Experience ASC\n",
        "    LIMIT 2\n",
        "    ```\n",
        "\n",
        "    Dont include ``` and \\n in the output\n",
        "\n",
        "    {input}\"\"\"\n",
        "    response = palm.generate_text(**defaults, prompt=prompt)\n",
        "    return response.result"
      ],
      "metadata": {
        "id": "7Q12j6RDBAyh"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_answer(\"To find employees names who know 'Pandas'?\")"
      ],
      "metadata": {
        "id": "reaCtY_WBAu-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "df4f2450-adcc-48a9-a773-78e7ad81963e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"MATCH (e:Employee)-[:HAS_RESUME]->(r:Resume)\\nWHERE 'Pandas' IN r.Skills\\nRETURN e.Employee_Name\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_query_and_return_key(input_query_result):\n",
        "    slash_n_pattern = r'[ \\n]+'\n",
        "    ret_pattern = r'RETURN\\s+(.*)'\n",
        "    replacement = ' '\n",
        "\n",
        "    cleaned_query = re.sub(slash_n_pattern, replacement, input_query_result)\n",
        "    if cleaned_query:\n",
        "        match = re.search(ret_pattern, cleaned_query)\n",
        "        if match:\n",
        "            extracted_string = match.group(1)\n",
        "        else:\n",
        "            extracted_string = \"\"\n",
        "    return cleaned_query, extracted_string"
      ],
      "metadata": {
        "id": "525XyJ4fBAsF"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_names_with_ampersand(names):\n",
        "    if len(names) == 0:\n",
        "        return \"\"\n",
        "    elif len(names) == 1:\n",
        "        return names[0]\n",
        "    else:\n",
        "        formatted_names = \", \".join(names[:-1]) + \" & \" + names[-1]\n",
        "        return formatted_names"
      ],
      "metadata": {
        "id": "rPA2qOh9BApU"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "driver = GraphDatabase.driver(\"bolt://18.207.214.172:7687\",auth=(\"neo4j\",\"month-fines-sirens\"))"
      ],
      "metadata": {
        "id": "P3OOzZruBAm5"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_cypher_on_neo4j(inp_query, inp_key):\n",
        "    out_list = []\n",
        "    with driver.session() as session:\n",
        "        result = session.run(inp_query)\n",
        "        for record in result:\n",
        "            out_list.append(record[inp_key])\n",
        "    driver.close()\n",
        "    if len(out_list) > 1:\n",
        "        return format_names_with_ampersand(out_list)\n",
        "    else:\n",
        "        return out_list[0]"
      ],
      "metadata": {
        "id": "VCntnD_mBAkU"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_query, gen_key = extract_query_and_return_key(get_answer(\"To retrieve the names of employees who Knows 'Flask'?\"))\n",
        "run_cypher_on_neo4j(gen_query, gen_key)"
      ],
      "metadata": {
        "id": "pwNKXnp2BAh4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a73e1a4d-fd0c-4e57-ebb9-a363aa723d79"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Omkar Pathak & KANDACE LOUDOR'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_exec_cypher(input_query):\n",
        "    gen_query, gen_key = extract_query_and_return_key(get_answer(input_query))\n",
        "    return run_cypher_on_neo4j(gen_query, gen_key)"
      ],
      "metadata": {
        "id": "E214yycqBAfn"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot(input, history=[]):\n",
        "    output = str(generate_and_exec_cypher(input))\n",
        "    history.append((input, output))\n",
        "    return history, history"
      ],
      "metadata": {
        "id": "e1v0hNEdBAc4"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio"
      ],
      "metadata": {
        "id": "tqqIZy3TBAaZ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gradio.Interface(fn = chatbot,\n",
        "             inputs = [\"text\",'state'],\n",
        "             outputs = [\"chatbot\",'state']).launch(debug = True)"
      ],
      "metadata": {
        "id": "GVC8T6arBAXy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6e0cb480-7388-4f34-be62-40c9fb4a27f0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://f8201c064f0edf9e32.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://f8201c064f0edf9e32.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-6d234cc3d37d>:3: DeprecationWarning: Using a driver after it has been closed is deprecated. Future versions of the driver will raise an error.\n",
            "  with driver.session() as session:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 456, in call_prediction\n",
            "    output = await route_utils.call_process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 232, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1522, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1144, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 674, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"<ipython-input-31-125151d1326a>\", line 2, in chatbot\n",
            "    output = str(generate_and_exec_cypher(input))\n",
            "  File \"<ipython-input-30-694492ab05d0>\", line 3, in generate_and_exec_cypher\n",
            "    return run_cypher_on_neo4j(gen_query, gen_key)\n",
            "  File \"<ipython-input-28-6d234cc3d37d>\", line 11, in run_cypher_on_neo4j\n",
            "    return out_list[0]\n",
            "IndexError: list index out of range\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 456, in call_prediction\n",
            "    output = await route_utils.call_process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 232, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1522, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1144, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 674, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"<ipython-input-31-125151d1326a>\", line 2, in chatbot\n",
            "    output = str(generate_and_exec_cypher(input))\n",
            "  File \"<ipython-input-30-694492ab05d0>\", line 3, in generate_and_exec_cypher\n",
            "    return run_cypher_on_neo4j(gen_query, gen_key)\n",
            "  File \"<ipython-input-28-6d234cc3d37d>\", line 11, in run_cypher_on_neo4j\n",
            "    return out_list[0]\n",
            "IndexError: list index out of range\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 501, in process_events\n",
            "    response = await self.call_prediction(awake_events, batch)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 465, in call_prediction\n",
            "    raise Exception(str(error) if show_error else None) from error\n",
            "Exception: None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://f8201c064f0edf9e32.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NqEhM1u6BAVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GwC-ImxPBASw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rx-BV5hBBAQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZpTT0ivIBAN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_eXtm-n0BALm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_OuN_gQcBAJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3D_VF3PNBAG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XR3DhDhsBAEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XNjVsrm3BAB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P2vGAMYdA__f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uQcjXxNDA_89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rd6Cc8GzA_6a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}